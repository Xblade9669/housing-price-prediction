{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10211,"databundleVersionId":111096,"sourceType":"competition"}],"dockerImageVersionId":30822,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import mean_squared_error\nimport numpy as np\n\n# File paths\ntrain_path = '/kaggle/input/home-data-for-ml-course/train.csv'\ntest_path = '/kaggle/input/home-data-for-ml-course/test.csv'\n\n# Load datasets\ntrain_data = pd.read_csv(train_path)\ntest_data = pd.read_csv(test_path)\n\n# Define target and features for training\ntarget = 'SalePrice'\nfeatures = [col for col in train_data.columns if col not in ['Id', target]]\n\n# Separate target from predictors\nX = train_data[features]\ny = train_data[target]\n\n# Identify numeric and categorical columns\nnumeric_cols = X.select_dtypes(include=['int64', 'float64']).columns\ncategorical_cols = X.select_dtypes(include=['object']).columns\n\n# Preprocessing for numeric and categorical data\nnumeric_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='mean')),\n    ('scaler', StandardScaler())\n])\n\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n])\n\n# Bundle preprocessing for numeric and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ])\n\n# Define the model\nmodel = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('model', LinearRegression())\n])\n\n# Fit the model\nmodel.fit(X, y)\n\n# Preprocess the test data and align features\nX_test = test_data[features]\nX_test_transformed = preprocessor.fit_transform(pd.concat([X, X_test]))\n\n# Align test data with training features\nX_test_transformed = X_test_transformed[len(X):]\n\n# Make predictions\npreds = model.named_steps['model'].predict(X_test_transformed)\n\n# Calculate RMSE on training data\npreds_train = model.predict(X)\nrmse_train = np.sqrt(mean_squared_error(y, preds_train))\nprint(f\"Root Mean Squared Error (RMSE) on training data: {rmse_train}\")\n\n# Print predictions\nprint(\"Predictions on test data:\", preds)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T03:41:59.757993Z","iopub.execute_input":"2024-12-25T03:41:59.758222Z","iopub.status.idle":"2024-12-25T03:42:02.465821Z","shell.execute_reply.started":"2024-12-25T03:41:59.758201Z","shell.execute_reply":"2024-12-25T03:42:02.465153Z"}},"outputs":[{"name":"stdout","text":"Root Mean Squared Error (RMSE) on training data: 226641336389606.06\nPredictions on test data: [ 1.96605462e+14 -8.65256367e+13  9.80679338e+12 ... -2.06910301e+13\n -1.90453238e+13 -2.35330790e+13]\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import mean_squared_error\nimport numpy as np\n\n# File paths\ntrain_path = '/kaggle/input/home-data-for-ml-course/train.csv'\ntest_path = '/kaggle/input/home-data-for-ml-course/test.csv'\n\n# Load datasets\ntrain_data = pd.read_csv(train_path)\ntest_data = pd.read_csv(test_path)\n\n# Define target and features for training\ntarget = 'SalePrice'\nfeatures = [col for col in train_data.columns if col not in ['Id', target]]\n\n# Separate target from predictors\nX = train_data[features]\ny = train_data[target]\n\n# Identify numeric and categorical columns\nnumeric_cols = X.select_dtypes(include=['int64', 'float64']).columns\ncategorical_cols = X.select_dtypes(include=['object']).columns\n\n# Preprocessing for numeric and categorical data\nnumeric_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='mean')),\n    ('scaler', StandardScaler())\n])\n\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n])\n\n# Bundle preprocessing for numeric and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ])\n\n# Define the model\nmodel = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('model', LinearRegression())\n])\n\n# Fit the model\nmodel.fit(X, y)\n\n# Preprocess the test data and align features\nX_test = test_data[features]\nX_test_transformed = preprocessor.fit_transform(pd.concat([X, X_test]))\n\n# Align test data with training features\nX_test_transformed = X_test_transformed[len(X):]\n\n# Make predictions\npreds = model.named_steps['model'].predict(X_test_transformed)\n\n# Calculate RMSE on training data\npreds_train = model.predict(X)\nrmse_train = np.sqrt(mean_squared_error(y, preds_train))\nprint(f\"Root Mean Squared Error (RMSE) on training data: {rmse_train}\")\n\n# Save predictions to a CSV file\noutput = pd.DataFrame({'Id': test_data['Id'], 'SalePrice': preds})\noutput_path = '/kaggle/working/submission.csv'\noutput.to_csv(output_path, index=False)\n\nprint(f\"Submission file saved to {output_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T03:45:52.630441Z","iopub.execute_input":"2024-12-25T03:45:52.630718Z","iopub.status.idle":"2024-12-25T03:45:52.919354Z","shell.execute_reply.started":"2024-12-25T03:45:52.630700Z","shell.execute_reply":"2024-12-25T03:45:52.918562Z"}},"outputs":[{"name":"stdout","text":"Root Mean Squared Error (RMSE) on training data: 226641336389606.06\nSubmission file saved to /kaggle/working/submission.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import mean_squared_error\nimport numpy as np\n\n# File paths\ntrain_path = '/kaggle/input/home-data-for-ml-course/train.csv'\ntest_path = '/kaggle/input/home-data-for-ml-course/test.csv'\n\n# Load datasets\ntrain_data = pd.read_csv(train_path)\ntest_data = pd.read_csv(test_path)\n\n# Define target and features for training\ntarget = 'SalePrice'\nfeatures = [col for col in train_data.columns if col not in ['Id', target]]\n\n# Separate target from predictors\nX = train_data[features]\ny = train_data[target]\n\n# Identify numeric and categorical columns\nnumeric_cols = X.select_dtypes(include=['int64', 'float64']).columns\ncategorical_cols = X.select_dtypes(include=['object']).columns\n\n# Preprocessing for numeric and categorical data\nnumeric_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='mean')),\n    ('scaler', StandardScaler())\n])\n\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n])\n\n# Bundle preprocessing for numeric and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ])\n\n# Define the model\nmodel = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('model', RandomForestRegressor(n_estimators=100, random_state=42))\n])\n\n# Fit the model\nmodel.fit(X, y)\n\n# Preprocess the test data and align features\nX_test = test_data[features]\nX_test_transformed = preprocessor.fit_transform(pd.concat([X, X_test]))\n\n# Align test data with training features\nX_test_transformed = X_test_transformed[len(X):]\n\n# Make predictions\npreds = model.named_steps['model'].predict(X_test_transformed)\n\n# Calculate RMSE on training data\npreds_train = model.predict(X)\nrmse_train = np.sqrt(mean_squared_error(y, preds_train))\nprint(f\"Root Mean Squared Error (RMSE) on training data: {rmse_train}\")\n\n# Save predictions to a CSV file\noutput = pd.DataFrame({'Id': test_data['Id'], 'SalePrice': preds})\noutput_path = '/kaggle/working/submission.csv'\noutput.to_csv(output_path, index=False)\n\nprint(f\"Submission file saved to {output_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T03:51:14.411599Z","iopub.execute_input":"2024-12-25T03:51:14.412023Z","iopub.status.idle":"2024-12-25T03:51:17.161060Z","shell.execute_reply.started":"2024-12-25T03:51:14.411986Z","shell.execute_reply":"2024-12-25T03:51:17.160203Z"}},"outputs":[{"name":"stdout","text":"Root Mean Squared Error (RMSE) on training data: 13718.86757473035\nSubmission file saved to /kaggle/working/submission.csv\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import mean_squared_error\nimport numpy as np\n\n# File paths\ntrain_path = '/kaggle/input/home-data-for-ml-course/train.csv'\ntest_path = '/kaggle/input/home-data-for-ml-course/test.csv'\n\n# Load datasets\ntrain_data = pd.read_csv(train_path)\ntest_data = pd.read_csv(test_path)\n\n# Define target and features for training\ntarget = 'SalePrice'\nfeatures = [col for col in train_data.columns if col not in ['Id', target]]\n\n# Separate target from predictors\nX = train_data[features]\ny = train_data[target]\n\n# Identify numeric and categorical columns\nnumeric_cols = X.select_dtypes(include=['int64', 'float64']).columns\ncategorical_cols = X.select_dtypes(include=['object']).columns\n\n# Remove outliers using Z-score\nfrom scipy.stats import zscore\nX_numeric = X[numeric_cols].copy()\nz_scores = zscore(X_numeric)\noutliers = (np.abs(z_scores) > 3).any(axis=1)\n\n# Filter out outliers\nX = X[~outliers]\ny = y[~outliers]\n\n# Preprocessing for numeric and categorical data\nnumeric_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='mean')),\n    ('scaler', StandardScaler())\n])\n\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n])\n\n# Bundle preprocessing for numeric and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ])\n\n# Define the model\nmodel = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('model', RandomForestRegressor(n_estimators=100, random_state=42))\n])\n\n# Fit the model\nmodel.fit(X, y)\n\n# Preprocess the test data and align features\nX_test = test_data[features]\nX_test_transformed = preprocessor.fit_transform(pd.concat([X, X_test]))\n\n# Align test data with training features\nX_test_transformed = X_test_transformed[len(X):]\n\n# Make predictions\npreds = model.named_steps['model'].predict(X_test_transformed)\n\n# Calculate RMSE on training data\npreds_train = model.predict(X)\nrmse_train = np.sqrt(mean_squared_error(y, preds_train))\nprint(f\"Root Mean Squared Error (RMSE) on training data: {rmse_train}\")\n\n# Save predictions to a CSV file\noutput = pd.DataFrame({'Id': test_data['Id'], 'SalePrice': preds})\noutput_path = '/kaggle/working/submission.csv'\noutput.to_csv(output_path, index=False)\n\nprint(f\"Submission file saved to {output_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T03:57:07.610581Z","iopub.execute_input":"2024-12-25T03:57:07.610842Z","iopub.status.idle":"2024-12-25T03:57:09.407226Z","shell.execute_reply.started":"2024-12-25T03:57:07.610825Z","shell.execute_reply":"2024-12-25T03:57:09.405759Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-f570ce1182e0>\u001b[0m in \u001b[0;36m<cell line: 75>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;31m# Make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_transformed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;31m# Calculate RMSE on training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    600\u001b[0m         Validate X whenever one tries to predict, apply, predict_proba.\"\"\"\n\u001b[1;32m    601\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No support for np.int64 index based sparse matrices\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    390\u001b[0m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: X has 274 features, but RandomForestRegressor is expecting 258 features as input."],"ename":"ValueError","evalue":"X has 274 features, but RandomForestRegressor is expecting 258 features as input.","output_type":"error"}],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import mean_squared_error\nimport numpy as np\n\n# File paths\ntrain_path = '/kaggle/input/home-data-for-ml-course/train.csv'\ntest_path = '/kaggle/input/home-data-for-ml-course/test.csv'\n\n# Load datasets\ntrain_data = pd.read_csv(train_path)\ntest_data = pd.read_csv(test_path)\n\n# Define target and features for training\ntarget = 'SalePrice'\nfeatures = [col for col in train_data.columns if col not in ['Id', target]]\n\n# Separate target from predictors\nX = train_data[features]\ny = train_data[target]\n\n# Identify numeric and categorical columns\nnumeric_cols = X.select_dtypes(include=['int64', 'float64']).columns\ncategorical_cols = X.select_dtypes(include=['object']).columns\n\n# Remove outliers using Z-score\nfrom scipy.stats import zscore\nX_numeric = X[numeric_cols].copy()\nz_scores = zscore(X_numeric)\noutliers = (np.abs(z_scores) > 3).any(axis=1)\n\n# Filter out outliers\nX = X[~outliers]\ny = y[~outliers]\n\n# Preprocessing for numeric and categorical data\nnumeric_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='mean')),\n    ('scaler', StandardScaler())\n])\n\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n])\n\n# Bundle preprocessing for numeric and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ])\n\n# Define the model\nmodel = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('model', RandomForestRegressor(n_estimators=100, random_state=42))\n])\n\n# Fit the model\nmodel.fit(X, y)\n\n# Preprocess the test data using the fitted preprocessor\nX_test = test_data[features]\nX_test_transformed = preprocessor.transform(X_test)\n\n# Make predictions\npreds = model.named_steps['model'].predict(X_test_transformed)\n\n# Calculate RMSE on training data\npreds_train = model.predict(X)\nrmse_train = np.sqrt(mean_squared_error(y, preds_train))\nprint(f\"Root Mean Squared Error (RMSE) on training data: {rmse_train}\")\n\n# Save predictions to a CSV file\noutput = pd.DataFrame({'Id': test_data['Id'], 'SalePrice': preds})\noutput_path = '/kaggle/working/submission.csv'\noutput.to_csv(output_path, index=False)\n\nprint(f\"Submission file saved to {output_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T03:59:42.450737Z","iopub.execute_input":"2024-12-25T03:59:42.451150Z","iopub.status.idle":"2024-12-25T03:59:44.138988Z","shell.execute_reply.started":"2024-12-25T03:59:42.451116Z","shell.execute_reply":"2024-12-25T03:59:44.137747Z"}},"outputs":[{"name":"stdout","text":"Root Mean Squared Error (RMSE) on training data: 8233.495171974348\nSubmission file saved to /kaggle/working/submission.csv\n","output_type":"stream"}],"execution_count":5}]}